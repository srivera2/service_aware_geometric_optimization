{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Parallel Scene Optimization\n",
    "\n",
    "This notebook parallelizes the boresight optimization across multiple scenes, utilizing all 8 of your RTX 6000 Ada GPUs.\n",
    "\n",
    "## Your Hardware\n",
    "- **8 × NVIDIA RTX 6000 Ada Generation** (49 GB each)\n",
    "- **~48 GB free** per GPU\n",
    "- **Total compute: 392 GB GPU memory**\n",
    "\n",
    "## Parallelization Strategy\n",
    "\n",
    "We'll use **Python multiprocessing** to run 8 scenes simultaneously (one per GPU). Here's why:\n",
    "\n",
    "| Approach | Pros | Cons | Best For |\n",
    "|----------|------|------|----------|\n",
    "| **Sequential** | Simple, predictable | Wastes 7 GPUs | Debugging |\n",
    "| **Threading** | Low overhead | GIL blocks CPU work | I/O-bound tasks |\n",
    "| **Multiprocessing** ✓ | True parallelism, GPU isolation | Memory overhead | GPU-heavy tasks |\n",
    "| **Distributed (Ray/Dask)** | Scales to clusters | Complex setup | Multi-machine |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concepts",
   "metadata": {},
   "source": [
    "## Key Concepts Explained\n",
    "\n",
    "### 1. Why Multiprocessing (not Threading)?\n",
    "\n",
    "Python has a **Global Interpreter Lock (GIL)** that prevents true parallel execution of Python code in threads. While GPU operations release the GIL, the scene loading and setup code is CPU-bound.\n",
    "\n",
    "```\n",
    "Threading:      [Thread 1]----[Thread 2]----[Thread 1]----  (interleaved)\n",
    "Multiprocessing: [Process 1]========================\n",
    "                 [Process 2]========================        (truly parallel)\n",
    "```\n",
    "\n",
    "### 2. Why `spawn` Start Method?\n",
    "\n",
    "CUDA requires the `spawn` start method (not `fork`) because:\n",
    "- `fork` copies the parent's CUDA context, causing conflicts\n",
    "- `spawn` creates fresh processes with their own CUDA contexts\n",
    "\n",
    "### 3. GPU Assignment Strategy\n",
    "\n",
    "We use **round-robin assignment**: Scene 0 → GPU 0, Scene 1 → GPU 1, ..., Scene 8 → GPU 0, etc.\n",
    "\n",
    "This ensures even distribution across all 8 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup and GPU Detection\n",
    "# ============================================================================\n",
    "# IMPORTANT: This cell must run FIRST before any CUDA operations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Set multiprocessing start method (required for CUDA)\n",
    "# This MUST be done before spawning any processes\n",
    "import torch.multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    print(\"✓ Multiprocessing start method set to 'spawn'\")\n",
    "except RuntimeError:\n",
    "    print(\"✓ Multiprocessing start method already set\")\n",
    "\n",
    "# Detect available GPUs\n",
    "print(f\"\\nGPU Detection:\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "print(f\"  GPUs detected: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Display GPU info\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    props = torch.cuda.get_device_properties(i)\n",
    "    free_mem = torch.cuda.mem_get_info(i)[0] / (1024**3)\n",
    "    total_mem = props.total_memory / (1024**3)\n",
    "    print(f\"  GPU {i}: {props.name} ({free_mem:.1f} GB free / {total_mem:.1f} GB total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Import Libraries\n",
    "# ============================================================================\n",
    "# These imports are for the MAIN process only.\n",
    "# Worker processes will import their own copies.\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Configuration\n",
    "# ============================================================================\n",
    "# Adjust these settings based on your needs\n",
    "\n",
    "# Parallelization settings\n",
    "NUM_WORKERS = 8          # One worker per GPU (optimal for your setup)\n",
    "GPU_IDS = [0, 1, 2, 3, 4, 5, 6, 7]  # All 8 GPUs\n",
    "\n",
    "# Scene settings\n",
    "PARENT_FOLDER = \"../scene/scenes\"\n",
    "MAX_SCENES = 50          # Process first N scenes (set to None for all)\n",
    "\n",
    "# Output settings\n",
    "OUTPUT_DIR = \"./parallel_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Zone validation thresholds (same as original notebook)\n",
    "VALIDATION_THRESHOLDS = {\n",
    "    'p10_min_dbm': -270.0,\n",
    "    'p10_max_dbm': -80.0,\n",
    "    'p90_min_dbm': -130.0,\n",
    "    'min_percentile_range_db': 15.0,\n",
    "}\n",
    "\n",
    "# Get scene directories\n",
    "scene_dirs = sorted([\n",
    "    d for d in os.listdir(PARENT_FOLDER)\n",
    "    if os.path.isdir(os.path.join(PARENT_FOLDER, d))\n",
    "])\n",
    "\n",
    "if MAX_SCENES:\n",
    "    scene_dirs = scene_dirs[:MAX_SCENES]\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "print(f\"  GPUs: {GPU_IDS}\")\n",
    "print(f\"  Scenes to process: {len(scene_dirs)}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nScenes: {scene_dirs[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worker-explanation",
   "metadata": {},
   "source": [
    "## The Worker Function\n",
    "\n",
    "The worker function is defined in **`src/parallel_worker.py`** (not in this notebook).\n",
    "\n",
    "### Why a Separate File?\n",
    "\n",
    "This is a fundamental limitation of **Jupyter + multiprocessing + spawn**:\n",
    "\n",
    "1. When you define a function in a notebook cell, it lives in `__main__`\n",
    "2. When multiprocessing spawns a child process, it creates a fresh Python interpreter\n",
    "3. The child process tries to import the worker function, but `__main__` doesn't exist there\n",
    "4. **Result:** `AttributeError: Can't get attribute 'process_single_scene' on <module '__main__'>`\n",
    "\n",
    "**Solution:** Put the worker in `src/parallel_worker.py` where it can be imported.\n",
    "\n",
    "### What the Worker Does\n",
    "\n",
    "```\n",
    "Main Process                    Worker Process 0 (GPU 0)\n",
    "    │                               │\n",
    "    │──── spawn ────────────────────│\n",
    "    │                               │── set CUDA_VISIBLE_DEVICES=0\n",
    "    │                               │── from parallel_worker import ...\n",
    "    │                               │── import torch, sionna, mitsuba\n",
    "    │                               │── load_scene(\"new_york\")\n",
    "    │                               │── optimize_boresight()\n",
    "    │                               │── evaluate_radiomap()\n",
    "    │◄─── return results ───────────│\n",
    "    │                               │── exit\n",
    "```\n",
    "\n",
    "Each worker:\n",
    "1. **Sets CUDA_VISIBLE_DEVICES** before importing GPU libraries\n",
    "2. **Imports libraries fresh** to get a clean CUDA context\n",
    "3. **Processes one scene** completely\n",
    "4. **Returns serializable results** (lists, not numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worker-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Import Worker Function\n",
    "# ============================================================================\n",
    "# The worker function is defined in a SEPARATE FILE (src/parallel_worker.py)\n",
    "# \n",
    "# WHY? When Python multiprocessing uses 'spawn' (required for CUDA), it creates\n",
    "# fresh Python interpreters. These child processes need to IMPORT the worker\n",
    "# function. But Jupyter notebooks run as `__main__`, which doesn't exist as an\n",
    "# importable module in child processes.\n",
    "#\n",
    "# By putting the worker in src/parallel_worker.py, child processes can do:\n",
    "#   from parallel_worker import process_single_scene\n",
    "#\n",
    "# This is a fundamental limitation of Jupyter + multiprocessing with spawn.\n",
    "\n",
    "from parallel_worker import process_single_scene\n",
    "\n",
    "print(\"✓ Worker function imported from src/parallel_worker.py\")\n",
    "print(\"  This allows spawned processes to import the function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executor-explanation",
   "metadata": {},
   "source": [
    "## The Parallel Executor\n",
    "\n",
    "We use `ProcessPoolExecutor` from Python's `concurrent.futures` module:\n",
    "\n",
    "```python\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    futures = [executor.submit(func, args) for args in work_items]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()  # Get result when ready\n",
    "```\n",
    "\n",
    "**Key features:**\n",
    "- `max_workers=8` creates 8 worker processes\n",
    "- `as_completed()` yields results as they finish (not in order)\n",
    "- Automatic process lifecycle management\n",
    "- Exception handling per-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Run Parallel Optimization\n",
    "# ============================================================================\n",
    "\n",
    "def run_parallel_optimization(scene_dirs, parent_folder, output_dir, num_workers, gpu_ids, validation_thresholds):\n",
    "    \"\"\"\n",
    "    Run optimization across multiple scenes in parallel.\n",
    "    \n",
    "    This function:\n",
    "    1. Prepares work items with GPU assignments\n",
    "    2. Spawns worker processes\n",
    "    3. Collects results as they complete\n",
    "    4. Saves incremental progress\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PARALLEL SCENE OPTIMIZATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nScenes: {len(scene_dirs)} | Workers: {num_workers} | GPUs: {gpu_ids}\")\n",
    "    print()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Prepare work items with ROUND-ROBIN GPU assignment\n",
    "    # =========================================================================\n",
    "    # Scene 0 → GPU 0, Scene 1 → GPU 1, ..., Scene 8 → GPU 0, etc.\n",
    "    work_items = [\n",
    "        (\n",
    "            scene_name,\n",
    "            gpu_ids[i % len(gpu_ids)],  # Round-robin\n",
    "            validation_thresholds,\n",
    "            parent_folder,\n",
    "            output_dir\n",
    "        )\n",
    "        for i, scene_name in enumerate(scene_dirs)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Execute in parallel using ProcessPoolExecutor\n",
    "    # =========================================================================\n",
    "    print(f\"Starting {num_workers} worker processes...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks to the pool\n",
    "        # Each task gets queued and assigned to an available worker\n",
    "        future_to_scene = {\n",
    "            executor.submit(process_single_scene, item): item[0]\n",
    "            for item in work_items\n",
    "        }\n",
    "        \n",
    "        # Process results as they complete (not in submission order)\n",
    "        # This allows us to update progress as each scene finishes\n",
    "        for future in as_completed(future_to_scene):\n",
    "            scene_name = future_to_scene[future]\n",
    "            completed += 1\n",
    "            \n",
    "            try:\n",
    "                _, result = future.result()\n",
    "                results[scene_name] = result\n",
    "                \n",
    "                # Print status\n",
    "                status = result.get('status', 'unknown')\n",
    "                if status == 'success':\n",
    "                    improvement = result['stats']['improvement_mean']\n",
    "                    elapsed = result['elapsed_time']\n",
    "                    print(f\"✓ [{completed}/{len(scene_dirs)}] {scene_name}: \"\n",
    "                          f\"+{improvement:.2f} dB in {elapsed:.1f}s (GPU {result['gpu_id']})\")\n",
    "                else:\n",
    "                    reason = result.get('reason', 'Unknown error')[:50]\n",
    "                    print(f\"✗ [{completed}/{len(scene_dirs)}] {scene_name}: {status} - {reason}\")\n",
    "                \n",
    "                # Save incremental progress\n",
    "                with open(os.path.join(output_dir, 'results_progress.json'), 'w') as f:\n",
    "                    json.dump(results, f, indent=2)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"✗ [{completed}/{len(scene_dirs)}] {scene_name}: Exception - {e}\")\n",
    "                results[scene_name] = {'status': 'error', 'reason': str(e)}\n",
    "            \n",
    "            # Progress estimate\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = completed / elapsed\n",
    "            remaining = len(scene_dirs) - completed\n",
    "            eta = remaining / rate if rate > 0 else 0\n",
    "            print(f\"   Progress: {100*completed/len(scene_dirs):.0f}% | \"\n",
    "                  f\"Rate: {rate*60:.1f} scenes/min | ETA: {eta/60:.1f} min\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # Final summary\n",
    "    # =========================================================================\n",
    "    total_time = time.time() - start_time\n",
    "    successful = sum(1 for r in results.values() if r.get('status') == 'success')\n",
    "    failed = sum(1 for r in results.values() if r.get('status') == 'failed')\n",
    "    errors = sum(1 for r in results.values() if r.get('status') == 'error')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total time:     {total_time/60:.1f} minutes ({total_time:.0f} seconds)\")\n",
    "    print(f\"Successful:     {successful}/{len(scene_dirs)}\")\n",
    "    print(f\"Failed zones:   {failed}\")\n",
    "    print(f\"Errors:         {errors}\")\n",
    "    \n",
    "    if successful > 0:\n",
    "        improvements = [\n",
    "            r['stats']['improvement_mean']\n",
    "            for r in results.values()\n",
    "            if r.get('status') == 'success'\n",
    "        ]\n",
    "        print(f\"\\nImprovement Statistics:\")\n",
    "        print(f\"  Mean:   {np.mean(improvements):+.2f} dB\")\n",
    "        print(f\"  Min:    {np.min(improvements):+.2f} dB\")\n",
    "        print(f\"  Max:    {np.max(improvements):+.2f} dB\")\n",
    "    \n",
    "    # Save final results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_file = os.path.join(output_dir, f'results_final_{timestamp}.json')\n",
    "    with open(final_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {final_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Execute Parallel Optimization\n",
    "# ============================================================================\n",
    "# This is the main execution cell - run this to start processing!\n",
    "\n",
    "results = run_parallel_optimization(\n",
    "    scene_dirs=scene_dirs,\n",
    "    parent_folder=PARENT_FOLDER,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    gpu_ids=GPU_IDS,\n",
    "    validation_thresholds=VALIDATION_THRESHOLDS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Results Analysis\n",
    "\n",
    "The following cells analyze the results from parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Results Analysis\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter successful results\n",
    "successful_results = {k: v for k, v in results.items() if v.get('status') == 'success'}\n",
    "failed_results = {k: v for k, v in results.items() if v.get('status') != 'success'}\n",
    "\n",
    "print(f\"Successful: {len(successful_results)} / {len(results)}\")\n",
    "print(f\"Failed: {len(failed_results)}\")\n",
    "\n",
    "if failed_results:\n",
    "    print(\"\\nFailed scenes:\")\n",
    "    for name, data in failed_results.items():\n",
    "        print(f\"  - {name}: {data.get('reason', 'Unknown')[:60]}\")\n",
    "\n",
    "if successful_results:\n",
    "    # Collect all zone power values\n",
    "    all_initial = np.concatenate([np.array(r['zone_power_initial']) for r in successful_results.values()])\n",
    "    all_optimized = np.concatenate([np.array(r['zone_power_optimized']) for r in successful_results.values()])\n",
    "    \n",
    "    # Per-scene improvements\n",
    "    improvements = [r['stats']['improvement_mean'] for r in successful_results.values()]\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"AGGREGATE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nInitial Configuration:\")\n",
    "    print(f\"  Mean:   {np.mean(all_initial):.2f} dBm\")\n",
    "    print(f\"  Median: {np.median(all_initial):.2f} dBm\")\n",
    "    print(f\"  P10:    {np.percentile(all_initial, 10):.2f} dBm\")\n",
    "    \n",
    "    print(f\"\\nOptimized Configuration:\")\n",
    "    print(f\"  Mean:   {np.mean(all_optimized):.2f} dBm\")\n",
    "    print(f\"  Median: {np.median(all_optimized):.2f} dBm\")\n",
    "    print(f\"  P10:    {np.percentile(all_optimized, 10):.2f} dBm\")\n",
    "    \n",
    "    print(f\"\\nImprovement:\")\n",
    "    print(f\"  Mean:   {np.mean(all_optimized) - np.mean(all_initial):+.2f} dB\")\n",
    "    print(f\"  Median: {np.median(all_optimized) - np.median(all_initial):+.2f} dB\")\n",
    "    print(f\"  P10:    {np.percentile(all_optimized, 10) - np.percentile(all_initial, 10):+.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Visualization\n",
    "# ============================================================================\n",
    "\n",
    "if successful_results:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # CDF comparison\n",
    "    ax1 = axes[0]\n",
    "    sorted_initial = np.sort(all_initial)\n",
    "    sorted_optimized = np.sort(all_optimized)\n",
    "    cdf = np.arange(1, len(sorted_initial) + 1) / len(sorted_initial)\n",
    "    \n",
    "    ax1.plot(sorted_initial, cdf * 100, linewidth=2, label='Initial', alpha=0.7)\n",
    "    ax1.plot(sorted_optimized, cdf * 100, linewidth=2, label='Optimized', alpha=0.7)\n",
    "    ax1.axhline(y=50, color='gray', linestyle='--', alpha=0.3)\n",
    "    ax1.axhline(y=10, color='red', linestyle='--', alpha=0.3)\n",
    "    ax1.set_xlabel('Signal Strength (dBm)')\n",
    "    ax1.set_ylabel('Cumulative Probability (%)')\n",
    "    ax1.set_title(f'CDF: Initial vs Optimized\\n({len(successful_results)} scenes)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement histogram\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(improvements, bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=np.mean(improvements), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(improvements):+.2f} dB')\n",
    "    ax2.axvline(x=0, color='gray', linestyle='-', alpha=0.5)\n",
    "    ax2.set_xlabel('Mean Power Improvement (dB)')\n",
    "    ax2.set_ylabel('Number of Scenes')\n",
    "    ax2.set_title('Distribution of Improvements')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Processing time by GPU\n",
    "    ax3 = axes[2]\n",
    "    gpu_times = {}\n",
    "    for name, data in successful_results.items():\n",
    "        gpu_id = data.get('gpu_id', 0)\n",
    "        if gpu_id not in gpu_times:\n",
    "            gpu_times[gpu_id] = []\n",
    "        gpu_times[gpu_id].append(data['elapsed_time'])\n",
    "    \n",
    "    gpu_ids_sorted = sorted(gpu_times.keys())\n",
    "    avg_times = [np.mean(gpu_times[g]) for g in gpu_ids_sorted]\n",
    "    ax3.bar(gpu_ids_sorted, avg_times, edgecolor='black', alpha=0.7)\n",
    "    ax3.set_xlabel('GPU ID')\n",
    "    ax3.set_ylabel('Average Processing Time (s)')\n",
    "    ax3.set_title('Processing Time by GPU')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'parallel_results_summary.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPlot saved to: {OUTPUT_DIR}/parallel_results_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**1. \"Can't get attribute 'process_single_scene' on module '__main__'\"**\n",
    "- This happens when the worker function is defined in the notebook instead of a separate file\n",
    "- **Solution:** The worker is now in `src/parallel_worker.py` - make sure you import it, not define it\n",
    "- Restart the kernel and run cells in order\n",
    "\n",
    "**2. \"CUDA out of memory\"**\n",
    "- Reduce `NUM_WORKERS` to run fewer scenes simultaneously\n",
    "- Each scene uses ~2-8 GB GPU memory\n",
    "\n",
    "**3. \"Cannot re-initialize CUDA in forked subprocess\"**\n",
    "- Make sure `mp.set_start_method('spawn')` runs BEFORE any CUDA imports\n",
    "- Restart the kernel and run cells in order\n",
    "\n",
    "**4. \"Processes hang or freeze\"**\n",
    "- Check `nvidia-smi` for GPU utilization\n",
    "- One scene may have complex geometry causing long ray tracing\n",
    "- Consider adding timeout to `future.result(timeout=3600)`\n",
    "\n",
    "**5. \"Results lost on error\"**\n",
    "- Incremental progress is saved to `results_progress.json`\n",
    "- Load it with: `results = json.load(open('parallel_results/results_progress.json'))`\n",
    "\n",
    "**6. \"ModuleNotFoundError: No module named 'parallel_worker'\"**\n",
    "- Make sure Cell 2 adds `../src` to the path before Cell 4 imports the worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: GPU Monitoring (run while processing)\n",
    "# ============================================================================\n",
    "# Run this cell in a separate terminal or notebook to monitor GPU usage\n",
    "\n",
    "# Uncomment to run nvidia-smi:\n",
    "# !nvidia-smi\n",
    "\n",
    "# Or for continuous monitoring (interrupt with Ctrl+C):\n",
    "# !watch -n 1 nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
